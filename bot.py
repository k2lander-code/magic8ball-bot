import telebot
from telebot.types import ReplyKeyboardMarkup, KeyboardButton
import time
import random
import os
import requests
import threading
from flask import Flask

app = Flask(__name__)

BOT_TOKEN = os.getenv('BOT_TOKEN')
HF_API_TOKEN = os.getenv('HF_API_TOKEN')

if not BOT_TOKEN:
    print("‚ùå BOT_TOKEN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    exit(1)

bot = telebot.TeleBot(BOT_TOKEN)

YES_NO_BASE = [
    '–î–∞, –æ–¥–Ω–æ–∑–Ω–∞—á–Ω–æ! ‚ú®',
    '–ù–µ—Ç, –Ω–µ —Å—É–¥—å–±–∞. üòî', 
    '–í–æ–∑–º–æ–∂–Ω–æ, –ø–æ–¥–æ–∂–¥–∏. ‚è≥',
    '–ê–±—Å–æ–ª—é—Ç–Ω–æ –≤–µ—Ä–Ω–æ! üëç',
    '–°–∫–æ—Ä–µ–µ –Ω–µ—Ç. ‚ùå',
    '–í–µ—Ä–æ—è—Ç–Ω–æ –¥–∞! üòä',
    '–ù–µ –∑–Ω–∞—é, –Ω–æ –≤–µ—Ä—é –≤ —Ç–µ–±—è. ‚ù§Ô∏è'
]

user_locks = {}

def get_keyboard():
    markup = ReplyKeyboardMarkup(resize_keyboard=True)
    button = KeyboardButton('üöÄ –û—Ç–ø—Ä–∞–≤–∏—Ç—å –∑–∞–ø—Ä–æ—Å –≤ –≤—Å–µ–ª–µ–Ω–Ω—É—é')
    markup.add(button)
    return markup

def get_working_model():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–∞–±–æ—Ç–∞—é—â—É—é –º–æ–¥–µ–ª—å"""
    models = [
        "microsoft/DialoGPT-small",  # –ú–µ–Ω—å—à–∞—è –≤–µ—Ä—Å–∏—è - —Ç–æ—á–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç
        "gpt2",                       # –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å
        "distilgpt2",                 # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è GPT-2
        "facebook/blenderbot-400M-distill"
    ]
    return models[0]  # –ù–∞—á–∏–Ω–∞–µ–º —Å DialoGPT-small

def test_huggingface_connection():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ —Ä–∞–±–æ—Ç–∞—é—â–µ–π –º–æ–¥–µ–ª–∏"""
    if not HF_API_TOKEN:
        return False, "‚ùå –¢–æ–∫–µ–Ω –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω"
    
    try:
        model = get_working_model()
        API_URL = f"https://api-inference.huggingface.co/models/{model}"
        headers = {"Authorization": f"Bearer {HF_API_TOKEN}"}
        
        test_prompt = "–°–∫–∞–∂–∏ –ø—Ä–∏–≤–µ—Ç"
        payload = {
            "inputs": test_prompt,
            "parameters": {"max_length": 20, "temperature": 0.7}
        }
        
        print(f"üîç –¢–µ—Å—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å: {model}")
        response = requests.post(API_URL, headers=headers, json=payload, timeout=30)
        
        print(f"üì° –°—Ç–∞—Ç—É—Å: {response.status_code}")
        
        if response.status_code == 200:
            result = response.json()
            if isinstance(result, list) and len(result) > 0:
                answer = result[0]['generated_text'].strip()
                return True, f"‚úÖ –ú–æ–¥–µ–ª—å {model} —Ä–∞–±–æ—Ç–∞–µ—Ç: {answer}"
            else:
                return False, f"‚ùå –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç {model}"
        elif response.status_code == 503:
            return False, f"‚ùå –ú–æ–¥–µ–ª—å {model} –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è... –ü–æ–ø—Ä–æ–±—É–π —á–µ—Ä–µ–∑ –º–∏–Ω—É—Ç—É"
        else:
            return False, f"‚ùå –û—à–∏–±–∫–∞ {response.status_code} –¥–ª—è {model}"
            
    except Exception as e:
        return False, f"‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ: {str(e)}"

def get_huggingface_prediction(question):
    """–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å —Ä–∞–±–æ—Ç–∞—é—â–µ–π –º–æ–¥–µ–ª—å—é"""
    if not HF_API_TOKEN:
        return random.choice(YES_NO_BASE)
    
    try:
        model = get_working_model()
        API_URL = f"https://api-inference.huggingface.co/models/{model}"
        headers = {"Authorization": f"Bearer {HF_API_TOKEN}"}
        
        # –ü—Ä–æ—Å—Ç–æ–π –ø—Ä–æ–º–ø—Ç
        prompt = f"–í–æ–ø—Ä–æ—Å: {question} –û—Ç–≤–µ—Ç:"
        
        payload = {
            "inputs": prompt,
            "parameters": {
                "max_length": 60,
                "temperature": 0.8,
                "do_sample": True,
            }
        }
        
        print(f"üîÑ –ó–∞–ø—Ä–æ—Å –∫ {model}: '{question}'")
        response = requests.post(API_URL, headers=headers, json=payload, timeout=30)
        
        print(f"üì° –°—Ç–∞—Ç—É—Å: {response.status_code}")
        
        if response.status_code == 200:
            result = response.json()
            print(f"üìä –û—Ç–≤–µ—Ç: {result}")
            
            if isinstance(result, list) and len(result) > 0:
                answer = result[0]['generated_text'].strip()
                if prompt in answer:
                    answer = answer.replace(prompt, '').strip()
                
                if answer and len(answer) > 3:
                    return answer
            
        return random.choice(YES_NO_BASE)
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        return random.choice(YES_NO_BASE)

@bot.message_handler(commands=['start'])
def start(message):
    user_id = message.from_user.id
    user_locks[user_id] = 0
    bot.send_message(
        message.chat.id, 
        "üîÆ *–ü—Ä–∏–≤–µ—Ç! –Ø –º–∞–≥–∏—á–µ—Å–∫–∏–π —à–∞—Ä!*", 
        parse_mode='Markdown', 
        reply_mup=get_keyboard()
    )

@bot.message_handler(commands=['test_ai'])
def test_ai(message):
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ò–ò"""
    connection_ok, connection_msg = test_huggingface_connection()
    
    if connection_ok:
        question = "–°—Ç–æ–∏—Ç –ª–∏ –º–Ω–µ —É—á–∏—Ç—å Python?"
        answer = get_huggingface_prediction(question)
        
        if answer in YES_NO_BASE:
            response = f"‚ùå –ò–ò –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª\nüì° {connection_msg}\nü§ñ –û—Ç–≤–µ—Ç: {answer}"
        else:
            response = f"‚úÖ –ò–ò –†–ê–ë–û–¢–ê–ï–¢!\nüì° {connection_msg}\nü§ñ –û—Ç–≤–µ—Ç: {answer}"
    else:
        response = f"‚ùå –ò–ò –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω\nüì° {connection_msg}"
    
    bot.send_message(message.chat.id, response, parse_mode='Markdown')

@bot.message_handler(commands=['model_info'])
def model_info(message):
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª—è—Ö"""
    connection_ok, connection_msg = test_huggingface_connection()
    
    info = f"""
ü§ñ *–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª—è—Ö:*

{connection_msg}

*–†–∞–±–æ—Ç–∞—é—â–∏–µ –º–æ–¥–µ–ª–∏:*
‚Ä¢ `microsoft/DialoGPT-small` - ‚úÖ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è
‚Ä¢ `gpt2` - üîÑ –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å  
‚Ä¢ `distilgpt2` - üöÄ –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è

*–ï—Å–ª–∏ –º–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è (503 –æ—à–∏–±–∫–∞):*
- –ü–æ–¥–æ–∂–¥–∏ 1-2 –º–∏–Ω—É—Ç—ã
- –ü–æ–ø—Ä–æ–±—É–π —Å–Ω–æ–≤–∞
- –ú–æ–¥–µ–ª—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≥—Ä—É–∑–∏—Ç—Å—è
    """
    bot.send_message(message.chat.id, info, parse_mode='Markdown')

@bot.message_handler(func=lambda message: True)
def handle_message(message):
    user_id = message.from_user.id
    current_time = time.time()
    
    if user_id in user_locks and current_time - user_locks[user_id] < 10:
        remaining = int(10 - (current_time - user_locks[user_id]))
        bot.send_message(message.chat.id, f"‚è≥ –ü–æ–¥–æ–∂–¥–∏ {remaining} —Å–µ–∫...", parse_mode='Markdown')
        return
    
    if message.text == 'üöÄ –û—Ç–ø—Ä–∞–≤–∏—Ç—å –∑–∞–ø—Ä–æ—Å –≤ –≤—Å–µ–ª–µ–Ω–Ω—É—é':
        question = "–ß—Ç–æ —à–µ–ø–Ω—ë—Ç –≤—Å–µ–ª–µ–Ω–Ω–∞—è —Å–µ–≥–æ–¥–Ω—è?"
    else:
        question = message.text
    
    user_locks[user_id] = current_time
    
    bot.send_message(message.chat.id, "üîÆ –¢—Ä—è—Å—ë–º —à–∞—Ä...", parse_mode='Markdown')
    time.sleep(2)
    
    if question != "–ß—Ç–æ —à–µ–ø–Ω—ë—Ç –≤—Å–µ–ª–µ–Ω–Ω–∞—è —Å–µ–≥–æ–¥–Ω—è?":
        answer = get_huggingface_prediction(question)
    else:
        answer = random.choice(YES_NO_BASE)
    
    bot.send_message(message.chat.id, f"üîÆ {answer}", parse_mode='Markdown')
    time.sleep(1)
    bot.send_message(message.chat.id, "–ì–æ—Ç–æ–≤ –∫ –Ω–æ–≤–æ–º—É –≤–æ–ø—Ä–æ—Å—É! üöÄ", reply_markup=get_keyboard())

@app.route('/')
def home():
    connection_ok, connection_msg = test_huggingface_connection()
    return f"""
    <html>
        <head><title>–ú–∞–≥–∏—á–µ—Å–∫–∏–π —à–∞—Ä</title></head>
        <body>
            <h1>üîÆ –ú–∞–≥–∏—á–µ—Å–∫–∏–π —à–∞—Ä</h1>
            <p>{connection_msg}</p>
            <p><a href="/test">–¢–µ—Å—Ç API</a></p>
        </body>
    </html>
    """

def start_bot_polling():
    print("üîÆ –ó–∞–ø—É—Å–∫–∞–µ–º –±–æ—Ç–∞...")
    while True:
        try:
            bot.polling(none_stop=True, interval=1)
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            time.sleep(10)

if __name__ == '__main__':
    print("üîÆ –ú–∞–≥–∏—á–µ—Å–∫–∏–π —à–∞—Ä –∑–∞–ø—É—â–µ–Ω!")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
    connection_ok, connection_msg = test_huggingface_connection()
    print(f"üì° {connection_msg}")
    
    bot_thread = threading.Thread(target=start_bot_polling, daemon=True)
    bot_thread.start()
    
    port = int(os.environ.get('PORT', 10000))
    app.run(host='0.0.0.0', port=port, debug=False)
